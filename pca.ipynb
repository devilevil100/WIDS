{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "F2E8ay-6qUzT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data_path = 'data.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(data_path, index_col=0)\n",
        "print(f\"dataset shape: {df.shape}\")\n",
        "\n",
        "index_values = df.index.astype(str)\n",
        "\n",
        "def extract_label(index_str):\n",
        "    parts = index_str.split('_')\n",
        "    if len(parts) > 0:\n",
        "        cancer_types = ['BRCA', 'KIRC', 'COAD', 'LUAD', 'PRAD']\n",
        "        for cancer in cancer_types:\n",
        "            if cancer in index_str.upper():\n",
        "                return cancer\n",
        "    return f\"group_{int(index_str) % 5}\" if index_str.isdigit() else \"Unknown\"\n",
        "\n",
        "y = pd.DataFrame({\n",
        "    'label': [extract_label(idx) for idx in index_values]\n",
        "}, index=df.index)\n",
        "\n",
        "X = df.copy()\n",
        "\n",
        "print(f\"labels extracted: {y['Label'].unique()}\")\n",
        "print(f\"label distribution:\\n{y['Label'].value_counts()}\")\n",
        "\n",
        "print(f\"dataset Dimensions: {X.shape}\")\n",
        "print(f\"no of samples: {X.shape[0]}\")\n",
        "print(f\"no of features (genes): {X.shape[1]}\")\n",
        "\n",
        "missing_count = X.isnull().sum().sum()\n",
        "print(f\"total missing values: {missing_count}\")\n",
        "\n",
        "print(f\"min value: {X.values.min():.6f}\")\n",
        "print(f\"ax value: {X.values.max():.6f}\")\n",
        "print(f\"mean value: {X.values.mean():.6f}\")\n",
        "print(f\"median value: {np.median(X.values):.6f}\")\n",
        "\n",
        "initial_shape = X.shape\n",
        "\n",
        "for col in X.columns:\n",
        "    if X[col].isnull().sum() > 0:\n",
        "        median_val = X[col].median()\n",
        "        X[col].fillna(median_val, inplace=True)\n",
        "\n",
        "y = y.loc[X.index]\n",
        "print(f\"shape before: {initial_shape}\")\n",
        "print(f\"shape after: {X.shape}\")\n",
        "print(f\"Rows removed: {initial_shape[0] - X.shape[0]}\")\n",
        "\n",
        "\n",
        "Q1 = X.quantile(0.25)\n",
        "Q3 = X.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "multiplier = 1.5\n",
        "lower_bound = Q1 - multiplier * IQR\n",
        "upper_bound = Q3 + multiplier * IQR\n",
        "\n",
        "outliers = ((X < lower_bound) | (X > upper_bound)).any(axis=1)\n",
        "n_outliers = outliers.sum()\n",
        "\n",
        "print(f\"no of outlier samples detected: {n_outliers}\")\n",
        "print(f\"Percentage of outliers: {(n_outliers/len(X))*100:.2f}%\")\n",
        "\n",
        "\n",
        "X_clipped = X.copy()\n",
        "for col in X.columns:\n",
        "    X_clipped[col] = np.clip(X_clipped[col], lower_bound[col], upper_bound[col])\n",
        "\n",
        "X = X_clipped\n",
        "\n",
        "variances = X.var()\n",
        "constant_features = variances[variances == 0].index.tolist()\n",
        "print(f\"no of constant features: {len(constant_features)}\")\n",
        "\n",
        "if len(constant_features) > 0:\n",
        "    X = X.drop(columns=constant_features)\n",
        "\n",
        "\n",
        "print(f\"Shape after removing constant features: {X.shape}\")\n",
        "\n",
        "initial_shape = X.shape\n",
        "variances = X.var()\n",
        "total_variance = variances.sum()\n",
        "variance_ratio = variances / total_variance\n",
        "threshold = 0.00001\n",
        "mask = variance_ratio > threshold\n",
        "X = X.loc[:, mask]\n",
        "\n",
        "print(f\"Shape before: {initial_shape}\")\n",
        "print(f\"Shape after: {X.shape}\")\n",
        "print(f\"Features removed: {initial_shape[1] - X.shape[1]}\")\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
        "\n",
        "print(f\"Mean of scaled data: {X_scaled.mean().mean():.6f}\")\n",
        "print(f\"Std of scaled data: {X_scaled.std().mean():.6f}\")\n",
        "print(f\"Scaled data shape: {X_scaled.shape}\")\n",
        "\n",
        "X_array = X_scaled.values\n",
        "n_samples, n_features = X_array.shape\n",
        "\n",
        "print(f\"Input array shape: {X_array.shape}\")\n",
        "\n",
        "mean_vector = np.mean(X_array, axis=0)\n",
        "X_centered = X_array - mean_vector\n",
        "print(f\"Data centered - mean: {np.mean(X_centered, axis=0).mean():.10f}\")\n",
        "\n",
        "cov_matrix = (1 / (n_samples - 1)) * np.dot(X_centered.T, X_centered)\n",
        "print(f\"Covariance matrix shape: {cov_matrix.shape}\")\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "print(f\"no of eigenvalues: {len(eigenvalues)}\")\n",
        "\n",
        "idx = np.argsort(eigenvalues)[::-1]\n",
        "eigenvalues_sorted = eigenvalues[idx]\n",
        "eigenvectors_sorted = eigenvectors[:, idx]\n",
        "\n",
        "eigenvalues_sorted = np.real(eigenvalues_sorted)\n",
        "eigenvectors_sorted = np.real(eigenvectors_sorted)\n",
        "\n",
        "print(f\"Eigenvalues sorted (top 10): {eigenvalues_sorted[:10]}\")\n",
        "\n",
        "total_variance = np.sum(eigenvalues_sorted)\n",
        "explained_variance_ratio = eigenvalues_sorted / total_variance\n",
        "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "print(f\"Total variance: {total_variance:.4f}\")\n",
        "print(f\"Explained variance ratio (first 10):\\n{explained_variance_ratio[:10]}\")\n",
        "\n",
        "n_components_90 = np.argmax(cumulative_variance_ratio >= 0.90) + 1\n",
        "n_components_95 = np.argmax(cumulative_variance_ratio >= 0.95) + 1\n",
        "n_components_99 = np.argmax(cumulative_variance_ratio >= 0.99) + 1\n",
        "\n",
        "print(f\"\\nComponents needed for 90% variance: {n_components_90}\")\n",
        "print(f\"Components needed for 95% variance: {n_components_95}\")\n",
        "print(f\"Components needed for 99% variance: {n_components_99}\")\n",
        "\n",
        "\n",
        "n_components = n_components_95\n",
        "components = eigenvectors_sorted[:, :n_components]\n",
        "\n",
        "print(f\"Selected {n_components} components for 95% variance retention\")\n",
        "print(f\"Principal components shape: {components.shape}\")\n",
        "\n",
        "\n",
        "X_transformed = np.dot(X_centered, components)\n",
        "\n",
        "print(f\"Transformed data shape: {X_transformed.shape}\")\n",
        "print(f\"Variance retained: {cumulative_variance_ratio[n_components-1]:.4f}\")\n",
        "\n",
        "X_pca = pd.DataFrame(X_transformed, columns=[f'PC{i+1}' for i in range(n_components)])\n",
        "\n",
        "for i in range(min(20, len(explained_variance_ratio))):\n",
        "    print(f\"  PC{i+1}: {explained_variance_ratio[i]:.6f} (Cumulative: {cumulative_variance_ratio[i]:.6f})\")\n",
        "\n",
        "print(f\"Dimensionality Reduction Summary:\")\n",
        "print(f\"  Original dimensions: {X_scaled.shape[1]}\")\n",
        "print(f\"  Reduced dimensions: {X_pca.shape[1]}\")\n",
        "print(f\"  Reduction percentage: {((1 - X_pca.shape[1]/X_scaled.shape[1])*100):.2f}%\")\n",
        "print(f\"  Total variance retained: {cumulative_variance_ratio[n_components-1]:.4f}\")\n"
      ]
    }
  ]
}